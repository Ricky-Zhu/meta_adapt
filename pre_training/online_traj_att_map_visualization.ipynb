{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# load the trajectory dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d856eeebb49df6e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import h5py\n",
    "import numpy as np\n",
    "from libero.lifelong.datasets import *\n",
    "from libero.libero.utils.dataset_utils import get_dataset_info\n",
    "from IPython.display import HTML\n",
    "import imageio\n",
    "from libero.libero import benchmark, get_libero_path, set_libero_default_path\n",
    "import os\n",
    "from termcolor import colored\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import cv2\n",
    "from libero.lifelong.models import *\n",
    "from libero.lifelong.utils import *\n",
    "model_path = '/home/ruiqi/projects/meta_adapt/scripts/experiments/LIBERO_OBJECT/PreTrainMultitask/BCViLTPolicy_seed10000/run_012/multitask_model_ep10.pth'\n",
    "checkpoint = torch.load(model_path)\n",
    "sd = checkpoint['state_dict']\n",
    "cfg = checkpoint['cfg']\n",
    "model = get_policy_class(cfg.policy.policy_type)(cfg, cfg.shape_meta)\n",
    "model.load_state_dict(sd)\n",
    "TASK_SUITE = cfg['task_creation']['task_suite']\n",
    "def construct_data(task_emb, agent_view_im, eye_in_hand_im):\n",
    "    data = {}\n",
    "    data['obs'] = {}\n",
    "    data['obs']['agentview_rgb'] = agent_view_im\n",
    "    data['obs']['eye_in_hand_rgb'] = eye_in_hand_im\n",
    "    data['task_emb'] = task_emb\n",
    "    return data\n",
    "\n",
    "\n",
    "def fetch_joint_att(data, model):\n",
    "    att_maps = model.get_spatial_summary(data)\n",
    "    att_maps_all_layer = []\n",
    "    for i in range(len(att_maps)):\n",
    "        att_maps_all_layer.append(att_maps[i])\n",
    "    att_mat = torch.stack(att_maps_all_layer).squeeze(1)\n",
    "\n",
    "    # Average the attention weights across all heads.\n",
    "    att_mat = torch.mean(att_mat, dim=1)\n",
    "\n",
    "    # To account for residual connections, we add an identity matrix to the\n",
    "    # attention matrix and re-normalize the weights.\n",
    "    residual_att = torch.eye(att_mat.size(1))\n",
    "    aug_att_mat = att_mat + residual_att\n",
    "    aug_att_mat = aug_att_mat / aug_att_mat.sum(dim=-1).unsqueeze(-1)\n",
    "\n",
    "    # Recursively multiply the weight matrices\n",
    "    joint_attentions = torch.zeros(aug_att_mat.size())\n",
    "    joint_attentions[0] = aug_att_mat[0]\n",
    "\n",
    "    for n in range(1, aug_att_mat.size(0)):\n",
    "        joint_attentions[n] = torch.matmul(aug_att_mat[n], joint_attentions[n - 1])\n",
    "    agentview_im = data['obs']['agentview_rgb'][0, 0, :].numpy().transpose(1, 2, 0)\n",
    "    eye_in_hand_im = data['obs']['eye_in_hand_rgb'][0, 0, :].numpy().transpose(1, 2, 0)\n",
    "    return joint_attentions, agentview_im, eye_in_hand_im\n",
    "\n",
    "\n",
    "def show_att_im(att_map, agentview_im, eye_in_hand_im):\n",
    "    v = att_map\n",
    "\n",
    "    # get the att of the spatial summary token (index 0) over all other tokens\n",
    "    agentview_att = v[0, 1:197]\n",
    "    agentview_att = agentview_att / agentview_att.sum()\n",
    "    # print(agentview_att.sum())\n",
    "    eye_in_hand_att = v[0, 197:197 + 196]\n",
    "    eye_in_hand_att = eye_in_hand_att / eye_in_hand_att.sum()\n",
    "    grid_size = 14\n",
    "\n",
    "    mask_agentview = agentview_att.reshape(grid_size, grid_size).detach().numpy()\n",
    "    mask_agentview = cv2.resize(mask_agentview / mask_agentview.max(), agentview_im.shape[:-1])[..., np.newaxis]\n",
    "\n",
    "    mask_eye_in_hand = eye_in_hand_att.reshape(grid_size, grid_size).detach().numpy()\n",
    "    mask_eye_in_hand = cv2.resize(mask_eye_in_hand / mask_eye_in_hand.max(), eye_in_hand_im.shape[:-1])[..., np.newaxis]\n",
    "\n",
    "    masked_im_a = agentview_im * mask_agentview\n",
    "    masked_im_e = eye_in_hand_im * mask_eye_in_hand\n",
    "    return masked_im_a[::-1], masked_im_e[::-1]\n",
    "\n",
    "\n",
    "def show_att_images(images_list, save_flag=False, view='a', task_id=0, traj_id=0):\n",
    "    # Define grid size (e.g., 3 rows and 4 columns)\n",
    "    rows = 4\n",
    "    cols = 7\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(18, 10))\n",
    "\n",
    "    # Flatten the axes array for easy iteration\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Plot each image in the grid\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < len(images_list):\n",
    "            ax.imshow(images_list[i])\n",
    "        ax.axis('off')  # Turn off axis\n",
    "\n",
    "    # Adjust spacing\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "\n",
    "    if not save_flag:\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(f'figs1/{TASK_SUITE}/t_{task_id}_d_{traj_id}_{view}.png', dpi=300, bbox_inches='tight')\n",
    "        \n",
    "\n",
    "\n",
    "def fetch_att_im_entire_traj(agentview_data_list, eye_in_hand_data_list, task_embs, task_id=0, traj_id=0):\n",
    "    \n",
    "    agent_att_list = []\n",
    "    eye_att_list = []\n",
    "\n",
    "    for i in range(len(agentview_data_list)):\n",
    "        temp = construct_data(task_embs, agentview_data_list[i], eye_in_hand_data_list[i])\n",
    "        joint_att, agentview_im, eye_in_hand_im = fetch_joint_att(temp, model)\n",
    "        im_a, im_e = show_att_im(joint_att[-1], agentview_im, eye_in_hand_im)\n",
    "        agent_att_list.append((im_a * 255).astype(np.uint8))\n",
    "        eye_att_list.append((im_e * 255).astype(np.uint8))\n",
    "\n",
    "    show_att_images(agent_att_list, save_flag=True, view='a', task_id=task_id, traj_id=traj_id)\n",
    "    show_att_images(eye_att_list, save_flag=True, view='e', task_id=task_id, traj_id=traj_id)\n",
    "\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "TASK_ID = 0\n",
    "\n",
    "online_traj_path = os.path.join('/', *model_path.split('/')[:-1], f'task_{TASK_ID}.pkl')\n",
    "\n",
    "#online_traj_path = \"/home/ruiqi/projects/meta_adapt/scripts/experiments/LIBERO_SPATIAL/PreTrainMultitask/BCViLTPolicy_seed10000/run_003/task_0.pkl\"\n",
    "with open(online_traj_path, 'rb') as f:\n",
    "    task_obs = pkl.load(f)\n",
    "    f.close()\n",
    "\n",
    "TRAJ_ID = 1  # [0,4]\n",
    "\n",
    "agentview_ims = [x['agentview_rgb'][TRAJ_ID] for x in task_obs]\n",
    "eye_in_hand_ims = [x['eye_in_hand_rgb'][TRAJ_ID] for x in task_obs]\n",
    "\n",
    "descriptions = []\n",
    "benchmark_dict = benchmark.get_benchmark_dict()\n",
    "benchmark_instance = benchmark_dict[TASK_SUITE]()\n",
    "task_description = benchmark_instance.get_task(TASK_ID).language\n",
    "descriptions.append(task_description)\n",
    "task_embs = get_task_embs(cfg, descriptions)\n",
    "# select several frames\n",
    "interval = len(agentview_ims) // 20\n",
    "selected_agentview_ims = []\n",
    "selected_eye_in_hand_ims = []\n",
    "selected_agentview_ims.append(agentview_ims[0][None, None, :].to('cpu'))\n",
    "selected_eye_in_hand_ims.append(eye_in_hand_ims[0][None, None, :].to('cpu'))\n",
    "for i in range(0, len(agentview_ims), interval):\n",
    "    selected_agentview_ims.append(agentview_ims[i][None, None, :].to('cpu'))\n",
    "    selected_eye_in_hand_ims.append(eye_in_hand_ims[i][None, None, :].to('cpu'))\n",
    "selected_agentview_ims.append(agentview_ims[-1][None, None, :].to('cpu'))\n",
    "selected_eye_in_hand_ims.append(eye_in_hand_ims[-1][None, None, :].to('cpu'))\n",
    "len(selected_agentview_ims)\n",
    "fetch_att_im_entire_traj(selected_agentview_ims,\n",
    "                         selected_eye_in_hand_ims,\n",
    "                         task_embs,\n",
    "                         task_id=TASK_ID,\n",
    "                         traj_id=TRAJ_ID)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-24T17:00:01.026752Z",
     "start_time": "2024-06-24T16:59:59.128089Z"
    }
   },
   "id": "c0d0199cfc0264e8",
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
