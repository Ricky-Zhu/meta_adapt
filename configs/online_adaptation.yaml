# @package _global_

adapt_demo_num_each_task: 5
post_adaptation_start_id: 5
bias_training_type: "lora_only"
num_workers: 4
learn_meta_update_inner_lrs: true
meta_display_interval: 5
update_procedure_batch_size: 32
n_epochs: 50
save_interval: 10
lora_rank: 8
meta_update_epochs: 10000
random_meta: false
meta_update_inner_lr: 0.4
meta_support_num: 5
meta_query_num: 15
seed: 10000
exp_dir: './experiments/lora_online_adaptation/'
pre_trained_model_path: '../scripts/experiments/LIBERO_OBJECT/PreTrainMultitask/BCViLTPolicy_seed10000/run_013/multitask_model_ep30.pth'
policy_type: 'LoraBCViLTPolicy'
optim_name: torch.optim.AdamW

meta_optim_kwargs:
    lr: 0.0001
    betas: [ 0.9, 0.999 ]
    weight_decay: 0.0001

optim_kwargs:
    lr: 0.0003
    betas: [0.9, 0.999]
    weight_decay: 0.0001

