lora_rank: 8
train_all_bias: false
adapt_demo_num_each_task: 10
adaptation_task_id: 8
n_epochs: 50
eval_every: 10
eval: false
n_eval: 20
eval_in_train: false
exp_dir: './experiments/lora_adaptation/'
seed: 100

optim_name: torch.optim.AdamW

optim_kwargs:
    lr: 0.0001
    betas: [0.9, 0.999]
    weight_decay: 0.0001